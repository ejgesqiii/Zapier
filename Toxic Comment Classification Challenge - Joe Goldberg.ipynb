{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up train dataframe into training and testing sets for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = int(round(0.8*len(df),0 ))\n",
    "\n",
    "train = df[:msk]\n",
    "test = df[msk:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vectorize comment_text and put in TF-IDF form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf = True, max_df = 0.5, stop_words='english')\n",
    "\n",
    "train_tfidf = vectorizer.fit_transform(train['comment_text'].values)\n",
    "test_tfidf = vectorizer.transform(test['comment_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(f_classif, percentile = 4)\n",
    "\n",
    "selector.fit(train_tfidf,train['toxic'].values)\n",
    "features_train_toxic = selector.transform(train_tfidf).toarray()\n",
    "features_test_toxic = selector.transform(test_tfidf).toarray()\n",
    "\n",
    "selector.fit(train_tfidf,train['severe_toxic'].values)\n",
    "features_train_severe_toxic = selector.transform(train_tfidf).toarray()\n",
    "features_test_severe_toxic = selector.transform(test_tfidf).toarray()\n",
    "\n",
    "selector.fit(train_tfidf,train['obscene'].values)\n",
    "features_train_obscene = selector.transform(train_tfidf).toarray()\n",
    "features_test_obscene = selector.transform(test_tfidf).toarray()\n",
    "\n",
    "selector.fit(train_tfidf,train['threat'].values)\n",
    "features_train_threat = selector.transform(train_tfidf).toarray()\n",
    "features_test_threat = selector.transform(test_tfidf).toarray()\n",
    "\n",
    "selector.fit(train_tfidf,train['insult'].values)\n",
    "features_train_insult = selector.transform(train_tfidf).toarray()\n",
    "features_test_insult = selector.transform(test_tfidf).toarray()\n",
    "\n",
    "selector.fit(train_tfidf,train['identity_hate'].values)\n",
    "features_train_identity_hate = selector.transform(train_tfidf).toarray()\n",
    "features_test_identity_hate = selector.transform(test_tfidf).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bayesian classifiers for: toxic, severe_toxic, obscene, threat, insult, and identity_hate comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_classifier = MultinomialNB()\n",
    "toxic_NB = toxic_classifier.fit(features_train_toxic, train['toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "severe_toxic_classifier = MultinomialNB()\n",
    "severe_toxic_NB = severe_toxic_classifier.fit(features_train_severe_toxic, train['severe_toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene_classifier = MultinomialNB()\n",
    "obscene_NB = obscene_classifier.fit(features_train_obscene, train['obscene'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_classifier = MultinomialNB()\n",
    "threat_NB = threat_classifier.fit(features_train_threat, train['threat'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_classifier = MultinomialNB()\n",
    "insult_NB = insult_classifier.fit(features_train_insult, train['insult'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_hate_classifier = MultinomialNB()\n",
    "identity_hate_NB = identity_hate_classifier.fit(features_train_identity_hate, train['identity_hate'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic = toxic_NB.predict(features_test_toxic)\n",
    "predicted_severe_toxic = severe_toxic_NB.predict(features_test_severe_toxic)\n",
    "predicted_obscene = obscene_NB.predict(features_test_obscene)\n",
    "predicted_threat = threat_NB.predict(features_test_threat)\n",
    "predicted_insult = insult_NB.predict(features_test_insult)\n",
    "predicted_identity_hate = identity_hate_NB.predict(features_test_identity_hate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">toxic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">severe_toxic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">obscene</th>\n",
       "      <th colspan=\"2\" halign=\"left\">threat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">insult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28815</td>\n",
       "      <td>1727</td>\n",
       "      <td>31575</td>\n",
       "      <td>274</td>\n",
       "      <td>30205</td>\n",
       "      <td>1012</td>\n",
       "      <td>31821</td>\n",
       "      <td>90</td>\n",
       "      <td>30261</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1310</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>657</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic       severe_toxic      obscene       threat     insult      \n",
       "col_0      0     1            0    1       0     1      0   1      0     1\n",
       "row_0                                                                     \n",
       "0      28815  1727        31575  274   30205  1012  31821  90  30261  1115\n",
       "1         62  1310           28   37      40   657      1   2     71   467"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mats=[]\n",
    "\n",
    "toxic_matrix = pd.crosstab(predicted_toxic, test['toxic'].values)\n",
    "severe_toxic_matrix = pd.crosstab(predicted_severe_toxic, test['severe_toxic'].values)\n",
    "obscene_matrix = pd.crosstab(predicted_obscene, test['obscene'].values)\n",
    "threat_matrix = pd.crosstab(predicted_threat, test['threat'].values)\n",
    "insult_matrix = pd.crosstab(predicted_insult, test['insult'].values)\n",
    "identity_hate_matrix = pd.crosstab(predicted_identity_hate, test['identity_hate'].values)\n",
    "\n",
    "conf_mats.append(toxic_matrix)\n",
    "conf_mats.append(severe_toxic_matrix)\n",
    "conf_mats.append(obscene_matrix)\n",
    "conf_mats.append(threat_matrix)\n",
    "conf_mats.append(insult_matrix)\n",
    "conf_mats.append(identity_hate_matrix)\n",
    "\n",
    "out = pd.concat(conf_mats,axis=1,keys = ['toxic','severe_toxic','obscene','threat','insult'])\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try non-linear loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['toxic'].values)\n",
    "predicted_toxic = toxic_classifier.predict(test_tfidf)  \n",
    "\n",
    "severe_toxic_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['severe_toxic'].values)\n",
    "predicted_severe_toxic = severe_toxic_classifier.predict(test_tfidf)   \n",
    "\n",
    "obscene_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['obscene'].values)\n",
    "predicted_obscene = obscene_classifier.predict(test_tfidf)   \n",
    "\n",
    "threat_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['threat'].values)\n",
    "predicted_threat = threat_classifier.predict(test_tfidf)   \n",
    "\n",
    "insult_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['insult'].values)\n",
    "predicted_insult = insult_classifier.predict(test_tfidf)   \n",
    "\n",
    "identity_hate_classifier = SGDClassifier(loss=\"hinge\", max_iter=10).fit(train_tfidf, train['identity_hate'].values)\n",
    "predicted_identity_hate = identity_hate_classifier.predict(test_tfidf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">toxic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">severe_toxic</th>\n",
       "      <th colspan=\"2\" halign=\"left\">obscene</th>\n",
       "      <th colspan=\"2\" halign=\"left\">threat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">insult</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28824</td>\n",
       "      <td>1646</td>\n",
       "      <td>31603.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>30189</td>\n",
       "      <td>700</td>\n",
       "      <td>31822.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>30188</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic       severe_toxic        obscene        threat       insult     \n",
       "col_0      0     1            0      1       0    1        0     1      0    1\n",
       "row_0                                                                         \n",
       "0      28824  1646      31603.0  311.0   30189  700  31822.0  92.0  30188  925\n",
       "1         53  1391          NaN    NaN      56  969      NaN   NaN    144  657"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mats=[]\n",
    "\n",
    "toxic_matrix = pd.crosstab(predicted_toxic, test['toxic'].values)\n",
    "severe_toxic_matrix = pd.crosstab(predicted_severe_toxic, test['severe_toxic'].values)\n",
    "obscene_matrix = pd.crosstab(predicted_obscene, test['obscene'].values)\n",
    "threat_matrix = pd.crosstab(predicted_threat, test['threat'].values)\n",
    "insult_matrix = pd.crosstab(predicted_insult, test['insult'].values)\n",
    "identity_hate_matrix = pd.crosstab(predicted_identity_hate, test['identity_hate'].values)\n",
    "\n",
    "conf_mats.append(toxic_matrix)\n",
    "conf_mats.append(severe_toxic_matrix)\n",
    "conf_mats.append(obscene_matrix)\n",
    "conf_mats.append(threat_matrix)\n",
    "conf_mats.append(insult_matrix)\n",
    "conf_mats.append(identity_hate_matrix)\n",
    "\n",
    "out = pd.concat(conf_mats,axis=1,keys = ['toxic','severe_toxic','obscene','threat','insult'])\n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate test predictions for competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = vectorizer.transform(test['comment_text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_toxic = toxic_classifier.predict(test_tfidf)  \n",
    "predicted_severe_toxic = severe_toxic_classifier.predict(test_tfidf)   \n",
    "predicted_obscene = obscene_classifier.predict(test_tfidf)   \n",
    "predicted_threat = threat_classifier.predict(test_tfidf)   \n",
    "predicted_insult = insult_classifier.predict(test_tfidf)   \n",
    "predicted_identity_hate = identity_hate_classifier.predict(test_tfidf)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_toxic'] = predicted_toxic\n",
    "test['predicted_severe_toxic'] = predicted_severe_toxic\n",
    "test['predicted_obscene'] = predicted_obscene\n",
    "test['predicted_threat'] = predicted_threat\n",
    "test['predicted_insult'] = predicted_insult\n",
    "test['predicted_identity_hate'] = predicted_identity_hate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Potential improvements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean Birds: Detecting Aggression and Bullying on Twitter (https://arxiv.org/pdf/1702.06877.pdf)\n",
    "    - word embedding with Word2Vec, sentiment scoring, hatebase db, user statistics, network based features\n",
    "Use pipelines to optimize model parameters and randomize train/test samples.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
